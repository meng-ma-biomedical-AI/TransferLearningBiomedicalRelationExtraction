{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOqFF-LlNDA6"
   },
   "source": [
    "# BioBERT für Relationsextraktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTGyZxSpNJY-"
   },
   "source": [
    "## Step 1: Korpusdaten verarbeiten\n",
    "Mit `lxml.etree` die Korpus-XML-Dateien verarbeiten.\n",
    "\n",
    "Siehe: [https://lxml.de/tutorial.html](https://lxml.de/tutorial.html)\n",
    "\n",
    "Am Ende geht es um die Paare, die eindeutig durch eine ID identifiziert werden (document ID, sentence ID, pair ID).\n",
    "\n",
    "* `id`\n",
    "* `label` bzw. `interaction`\n",
    "* `sentence`\n",
    "* `e1_span`\n",
    "* `e2_span`\n",
    "\n",
    "Beispielauszug aus dem BioInfer Korpus:\n",
    "\n",
    "```xml\n",
    "<corpus id=\"BioInfer\">\n",
    "  ...\n",
    "  <document id=\"BioInfer.d1\" origId=\"8001585\">\n",
    "    ...\n",
    "    <sentence id=\"BioInfer.d1.s1\" origId=\"235\" text=\"Birch profilin increased the critical concentration required for muscle and brain muscl polymerization in a concentration-dependent manner, supporting the notion of the formation of a heterologous complex between the plant protein and animal actin.\">\n",
    "      <entity charOffset=\"76-86\" id=\"BioInfer.d1.s1.e0\" origId=\"e.235.4\" text=\"brain actin\" type=\"Individual_protein\" />\n",
    "      <entity charOffset=\"6-13\" id=\"BioInfer.d1.s1.e1\" origId=\"e.235.5\" text=\"profilin\" type=\"Individual_protein\" />\n",
    "      <entity charOffset=\"65-70,82-86\" id=\"BioInfer.d1.s1.e2\" origId=\"e.235.6\" text=\"muscle actin\" type=\"Individual_protein\" />\n",
    "      <entity charOffset=\"242-246\" id=\"BioInfer.d1.s1.e3\" origId=\"e.235.7\" text=\"actin\" type=\"Individual_protein\" />\n",
    "      <pair e1=\"BioInfer.d1.s1.e0\" e2=\"BioInfer.d1.s1.e1\" id=\"BioInfer.d1.s1.p0\" interaction=\"True\" />\n",
    "      <pair e1=\"BioInfer.d1.s1.e0\" e2=\"BioInfer.d1.s1.e2\" id=\"BioInfer.d1.s1.p1\" interaction=\"False\" />\n",
    "      <pair e1=\"BioInfer.d1.s1.e0\" e2=\"BioInfer.d1.s1.e3\" id=\"BioInfer.d1.s1.p2\" interaction=\"False\" />\n",
    "      <pair e1=\"BioInfer.d1.s1.e1\" e2=\"BioInfer.d1.s1.e2\" id=\"BioInfer.d1.s1.p3\" interaction=\"True\" />\n",
    "      <pair e1=\"BioInfer.d1.s1.e1\" e2=\"BioInfer.d1.s1.e3\" id=\"BioInfer.d1.s1.p4\" interaction=\"True\" />\n",
    "      <pair e1=\"BioInfer.d1.s1.e2\" e2=\"BioInfer.d1.s1.e3\" id=\"BioInfer.d1.s1.p5\" interaction=\"False\" />\n",
    "    </sentence>\n",
    "    ...\n",
    "  </document>\n",
    "  ...\n",
    "</corpus>\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_OT41AAWiCp"
   },
   "source": [
    "Problematisch sind überlappende `charOffset`s:\n",
    "\n",
    "```xml\n",
    "<entities>\n",
    "    <entity charOffset=\"76-86\" id=\"BioInfer.d1.s1.e0\" origId=\"e.235.4\" text=\"brain actin\" type=\"Individual_protein\" />\n",
    "    <entity charOffset=\"65-70,82-86\" id=\"BioInfer.d1.s1.e2\" origId=\"e.235.6\" text=\"muscle actin\" type=\"Individual_protein\" />\n",
    "</entities>\n",
    "```\n",
    "\n",
    "Bei der Anonymisierung ersetzen wir den Teil mit der größeren Spanne durch `@PROTEIN$`.\n",
    "Bei den Positionsmarkierung setzen wir die Marker normal ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from tlbiore.data import corpus_processor, utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einstellungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aimed_train = '../data/raw/AIMed-train.xml'\n",
    "bioinfer_train = '../data/raw/BioInfer-train.xml'\n",
    "\n",
    "# Testdateien, für die wir die Predictions machen\n",
    "aimed_pred = '../data/raw/AIMed-test.xml'\n",
    "bioinfer_pred = '../data/raw/BioInfer-test.xml'\n",
    "\n",
    "data_path = '../data/ppi_hu/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verarbeiten die XML-Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_train_corpus = corpus_processor.process_corpora([aimed_train, bioinfer_train])\n",
    "ppi_pred_corpus = corpus_processor.process_corpora([aimed_pred, bioinfer_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier führen wir den Split aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_split_objects = ppi_train_corpus.get_sentences()\n",
    "train, dev, test = utils.train_dev_test_split(ppi_split_objects)\n",
    "    \n",
    "# Resampling \n",
    "mask = train.label == 1\n",
    "train_interaction = train[mask]\n",
    "train_no_interaction = train[~mask]\n",
    "\n",
    "# Oversampling\n",
    "oversampled_interaction = train_interaction.sample(len(train_no_interaction),replace=True)\n",
    "train_os = pd.concat([oversampled_interaction, train_no_interaction])\n",
    "\n",
    "# Undersampling\n",
    "undersampled_no_interaction = train_no_interaction.sample(len(train_interaction))\n",
    "train_us = pd.concat([train_interaction, undersampled_no_interaction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ppi_pred_corpus.get_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGny69cGl9_G"
   },
   "source": [
    "## Step 2: Vorbereitung für BERT\n",
    "\n",
    "1. Unser Hauptpaper: **\"A BERT-based Universal Model for Both Within- and Cross-sentence Clinical Temporal Relation Extraction\"** markiert die Positionen der Entitäten durch spezielle Non-XML Tags.\n",
    "Wir könnten zum Beispiel `ps` (protein start) und `pe` (protein end) verwenden.\n",
    "2. Alibaba: **\"Enriching Pre-trained Language Model with Entity Information for Relation Classification\"** markieren die Position der ersten Entität durch $-Zeichen und die Position der zweiten Entität durch #-Zeichen. \n",
    "3. BioBERT: **\"BioBERT: a pre-trained biomedical language representation model for biomedical text mining\"** anonymisiert die Entitäten. Bei uns würde man die Entitäten einfach durch `@PROTEIN$` ersetzen. Evtl. muss man die Entitäten z.B. durch eine Zahl am Ende unterscheiden?\n",
    "\n",
    "Um diese speziellen Tokens - `ps` (protein start) und `pe` (protein end) -zu verwenden, müssen wir unser BioBERT Vokabular anpassen.\n",
    "\n",
    "**HOW?**\n",
    "\n",
    "Jedenfalls müssen wir unsere Pandas DataFrames den Ansätzen entsprechend anpassen. Dann müssen wir die jeweils in Train, Dev, Test aufteilen und am als .jsonl-Dateien abspeichern, um später mit HuggingFace arbeiten zu können.\n",
    "\n",
    "Hier für sollte reichen:\n",
    "\n",
    "*   `id`\n",
    "*   `sentence`\n",
    "*   `label`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UVcHp8TQ1tl"
   },
   "source": [
    "### 2.1 Ansätze 1 & 2: Markiere die Positionen der Entitäten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWo_brirMkY0"
   },
   "source": [
    "#### 2.1.1: Unser Hauptpaper: \"A BERT-based Universal Model for Both Within- and Cross-sentence Clinical Temporal Relation Extraction\" \n",
    "Hier markieren wir die Entitäten mit `ps` (protein start) und `pe` (protein end).\n",
    "Wir müssten uns das Vokabular anschauen und evtl. etwas anpassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_train = corpus_processor.prepare_data_lin(train)\n",
    "lin_dev = corpus_processor.prepare_data_lin(dev)\n",
    "lin_test = corpus_processor.prepare_data_lin(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_sTcb3_TBq1"
   },
   "source": [
    "Exportieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.export_jsonl(lin_train, data_path + 'lin/train.jsonl')\n",
    "utils.export_jsonl(lin_dev, data_path + 'lin/dev.jsonl')\n",
    "utils.export_jsonl(lin_test, data_path + 'lin/test.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog mit den \"richtigen\" Testdaten ohne Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pred = corpus_processor.prepare_data_lin(pred)\n",
    "utils.export_jsonl(lin_pred, data_path + 'lin/predict.jsonl', with_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampled train\n",
    "lin_train_os = corpus_processor.prepare_data_lin(train_os)\n",
    "lin_train_us = corpus_processor.prepare_data_lin(train_us)\n",
    "utils.export_jsonl(lin_train_os, data_path + 'lin/train_os.jsonl')\n",
    "utils.export_jsonl(lin_train_us, data_path + 'lin/train_us.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-_B_Nw1SPDg"
   },
   "source": [
    "#### 2.1.2: Alibaba: \"Enriching Pre-trained Language Model with Entity Information for Relation Classification\" \n",
    "Sie markieren die Position der ersten Entität durch `$`-Zeichen und die Position der zweiten Entität durch `#`-Zeichen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2660,
     "status": "ok",
     "timestamp": 1576852239238,
     "user": {
      "displayName": "Phuc Tran Truong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAtDttng0SFYf-Lu8w00DjUN3gtub9PgQuw64xDvA=s64",
      "userId": "03181581394635037704"
     },
     "user_tz": -60
    },
    "id": "4Zf4OdjgvwEM",
    "outputId": "9520d332-599c-4a28-ebe3-8790d79eda4a"
   },
   "outputs": [],
   "source": [
    "ali_train = corpus_processor.prepare_data_ali(train)\n",
    "ali_dev = corpus_processor.prepare_data_ali(dev)\n",
    "ali_test = corpus_processor.prepare_data_ali(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwPb91UPTEjt"
   },
   "source": [
    "Exportieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1576852248359,
     "user": {
      "displayName": "Phuc Tran Truong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAtDttng0SFYf-Lu8w00DjUN3gtub9PgQuw64xDvA=s64",
      "userId": "03181581394635037704"
     },
     "user_tz": -60
    },
    "id": "zBeUozzZTFag",
    "outputId": "e82180c2-221b-4d99-a43f-93de08f6b7d5"
   },
   "outputs": [],
   "source": [
    "utils.export_jsonl(ali_train, data_path + 'ali/train.jsonl')\n",
    "utils.export_jsonl(ali_dev, data_path + 'ali/dev.jsonl')\n",
    "utils.export_jsonl(ali_test, data_path + 'ali/test.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog mit den \"richtigen\" Testdaten ohne Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_pred = corpus_processor.prepare_data_ali(pred)\n",
    "utils.export_jsonl(ali_pred, data_path + 'ali/predict.jsonl', with_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampled train\n",
    "ali_train_os = corpus_processor.prepare_data_ali(train_os)\n",
    "ali_train_us = corpus_processor.prepare_data_ali(train_us)\n",
    "utils.export_jsonl(ali_train_os, data_path + 'ali/train_os.jsonl')\n",
    "utils.export_jsonl(ali_train_us, data_path + 'ali/train_us.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HQvmSYaGHYD"
   },
   "source": [
    "### 2.2: BioBERT: \"BioBERT: a pre-trained biomedical language representation model for biomedical text mining\" \n",
    "Sie anonymisieren die Entitäten. Bei uns würde man die Entitäten einfach durch `@PROTEIN$` ersetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2588,
     "status": "ok",
     "timestamp": 1576852279456,
     "user": {
      "displayName": "Phuc Tran Truong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAtDttng0SFYf-Lu8w00DjUN3gtub9PgQuw64xDvA=s64",
      "userId": "03181581394635037704"
     },
     "user_tz": -60
    },
    "id": "Z5w3GUi0GV3-",
    "outputId": "03a2c7c8-e9a6-4ef7-d0f1-6175aecd471a"
   },
   "outputs": [],
   "source": [
    "lee_train = corpus_processor.prepare_data_lee(train)\n",
    "lee_dev = corpus_processor.prepare_data_lee(dev)\n",
    "lee_test = corpus_processor.prepare_data_lee(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZNKeZ37AMiIo"
   },
   "source": [
    "Exportieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1576852325240,
     "user": {
      "displayName": "Phuc Tran Truong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAtDttng0SFYf-Lu8w00DjUN3gtub9PgQuw64xDvA=s64",
      "userId": "03181581394635037704"
     },
     "user_tz": -60
    },
    "id": "uuK30OLzMVJI",
    "outputId": "0f27a487-970e-4847-8c58-af7fbd011b77"
   },
   "outputs": [],
   "source": [
    "utils.export_jsonl(lee_train, data_path + 'lee/train.jsonl')\n",
    "utils.export_jsonl(lee_dev, data_path + 'lee/dev.jsonl')\n",
    "utils.export_jsonl(lee_test, data_path + 'lee/test.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog mit den \"richtigen\" Testdaten ohne Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lee_pred = corpus_processor.prepare_data_lee(pred)\n",
    "utils.export_jsonl(lee_pred, data_path + 'lee/predict.jsonl', with_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampled train\n",
    "lee_train_os = corpus_processor.prepare_data_lee(train_os)\n",
    "lee_train_us = corpus_processor.prepare_data_lee(train_us)\n",
    "utils.export_jsonl(lee_train_os, data_path + 'lee/train_os.jsonl')\n",
    "utils.export_jsonl(lee_train_us, data_path + 'lee/train_us.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Korpusdaten-Bearbeiten.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (tlbiore)",
   "language": "python",
   "name": "tlbiore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}